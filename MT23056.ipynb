{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8197453,"sourceType":"datasetVersion","datasetId":4855760}],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/content/drive/MyDrive/IR_Assignment4/Reviews.csv\")\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n\nfile_path = '/content/drive/MyDrive/IR_Assignment4/Reviews.csv'\ndf = pd.read_csv(file_path)\n\ndef preprocess_text(text):\n    if pd.isna(text):\n        return \"\"\n    text = str(text).lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    tokens = [token.lemma_ for token in nlp(text) if not token.is_stop]\n    return ' '.join(tokens)\n\ndf['Summary'] = df['Summary'].apply(preprocess_text)\ndf['Text'] = df['Text'].apply(preprocess_text)\n\noutput_file_path = '/content/drive/MyDrive/IR_Assignment4/preprocess.csv'\ndf.to_csv(output_file_path, index=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/content/drive/MyDrive/IR_Assignment4/preprocess.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n\nfile_path = '/content/drive/MyDrive/IR_Assignment4/preprocess.csv'\ndf = pd.read_csv(file_path)\n\ndef tokenize_text(text):\n    if pd.isna(text):\n        return []\n    tokens = [token.lemma_ for token in nlp(text) if not token.is_stop]\n    return tokens\n\ndf['Summary_tokens'] = df['Summary'].apply(tokenize_text)\ndf['Text_tokens'] = df['Text'].apply(tokenize_text)\n\noutput_file_path = '/content/drive/MyDrive/IR_Assignment4/preprocess_tokens.csv'\ndf.to_csv(output_file_path, index=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/content/drive/MyDrive/IR_Assignment4/preprocess_tokens.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm\nfrom rouge import Rouge\nimport csv","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:18:35.945755Z","iopub.execute_input":"2024-04-22T18:18:35.946176Z","iopub.status.idle":"2024-04-22T18:18:35.952012Z","shell.execute_reply.started":"2024-04-22T18:18:35.946148Z","shell.execute_reply":"2024-04-22T18:18:35.950984Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:12:20.065028Z","iopub.execute_input":"2024-04-22T18:12:20.065949Z","iopub.status.idle":"2024-04-22T18:12:34.696116Z","shell.execute_reply.started":"2024-04-22T18:12:20.065909Z","shell.execute_reply":"2024-04-22T18:12:34.694764Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"data_path = '/kaggle/input/preprocess/preprocess.csv'\nreview_data = pd.read_csv(data_path).head(10000)\nselected_columns = ['Score', 'Text', 'Summary']\ntraining_data, testing_data = train_test_split(review_data[selected_columns], test_size=0.25, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:18:08.650861Z","iopub.execute_input":"2024-04-22T19:18:08.651341Z","iopub.status.idle":"2024-04-22T19:18:12.216585Z","shell.execute_reply.started":"2024-04-22T19:18:08.651305Z","shell.execute_reply":"2024-04-22T19:18:12.215469Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class ReviewSummarizationDataset(Dataset):\n    def __init__(self, dataset_frame, text_encoder, max_seq_length):\n        self.dataset_frame = dataset_frame\n        self.text_encoder = text_encoder\n        self.max_seq_length = max_seq_length\n        # Set padding token explicitly\n        self.text_encoder.pad_token = self.text_encoder.eos_token  # Set padding token to end of sequence token\n\n    def __len__(self):\n        return len(self.dataset_frame)\n\n    def __getitem__(self, index):\n        review_content = str(self.dataset_frame.iloc[index]['Text'])\n        summary_content = str(self.dataset_frame.iloc[index]['Summary'])\n\n        # Combine review content and summary content\n        full_text = f\"Review Content: {review_content}\\nSummary: {summary_content}\"\n\n        # Tokenize the full text\n        tokenized_inputs = self.text_encoder.encode_plus(\n            full_text,\n            add_special_tokens=True,\n            max_length=self.max_seq_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        token_ids = tokenized_inputs['input_ids'].squeeze(0)\n        mask = tokenized_inputs['attention_mask'].squeeze(0)\n\n        # Convert score to tensor\n        target_label = torch.tensor(self.dataset_frame.iloc[index]['Score'])\n\n        return {\n            'input_ids': token_ids,\n            'attention_mask': mask,\n            'label': target_label\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:18:23.047793Z","iopub.execute_input":"2024-04-22T19:18:23.048211Z","iopub.status.idle":"2024-04-22T19:18:23.059837Z","shell.execute_reply.started":"2024-04-22T19:18:23.048178Z","shell.execute_reply":"2024-04-22T19:18:23.058600Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ngpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n\ntraining_dataset = ReviewSummarizationDataset(training_data, gpt2_tokenizer, max_seq_length=128)\ntraining_dataloader = DataLoader(training_dataset, batch_size=10, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:18:26.984996Z","iopub.execute_input":"2024-04-22T19:18:26.986206Z","iopub.status.idle":"2024-04-22T19:18:27.914933Z","shell.execute_reply.started":"2024-04-22T19:18:26.986166Z","shell.execute_reply":"2024-04-22T19:18:27.913989Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-5\nnum_epochs = 3\nwarmup_steps = int(0.1 * len(training_dataloader) * num_epochs)\noptimizer = AdamW(gpt2_model.parameters(), lr=learning_rate)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=len(training_dataloader) * num_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:18:32.309266Z","iopub.execute_input":"2024-04-22T19:18:32.310220Z","iopub.status.idle":"2024-04-22T19:18:32.321015Z","shell.execute_reply.started":"2024-04-22T19:18:32.310186Z","shell.execute_reply":"2024-04-22T19:18:32.319933Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngpt2_model.to(device)\ngpt2_model.train()\n\nfor epoch in range(num_epochs):\n    for batch in training_dataloader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        outputs = gpt2_model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n        training_loss = outputs.loss\n        training_loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {training_loss.item()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:18:37.326577Z","iopub.execute_input":"2024-04-22T19:18:37.327371Z","iopub.status.idle":"2024-04-22T19:31:40.542499Z","shell.execute_reply.started":"2024-04-22T19:18:37.327333Z","shell.execute_reply":"2024-04-22T19:31:40.541131Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1/3, Loss: 1.9871684312820435\nEpoch 2/3, Loss: 2.309363842010498\nEpoch 3/3, Loss: 2.6320555210113525\n","output_type":"stream"}]},{"cell_type":"code","source":"review_data_path = '/kaggle/input/preprocess/preprocess.csv'\noutput_file = 'rouge_scores.csv' \nnum_rows_to_read = 200","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:31:45.964684Z","iopub.execute_input":"2024-04-22T19:31:45.965664Z","iopub.status.idle":"2024-04-22T19:31:45.970360Z","shell.execute_reply.started":"2024-04-22T19:31:45.965625Z","shell.execute_reply":"2024-04-22T19:31:45.969252Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def generate_summary(review_text):\n    inputs = gpt2_tokenizer.encode_plus(\n        review_text,\n        return_tensors=\"pt\",\n        max_length=1024,\n        truncation=True\n    )\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n    fine_tuned_model = GPT2LMHeadModel.from_pretrained('fine_tuned_gpt2_2').to(device)\n    summary_ids = fine_tuned_model.generate(inputs['input_ids'], max_length=1024, num_beams=4, early_stopping=True)\n    generated_summary = gpt2_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return generated_summary","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:31:49.586816Z","iopub.execute_input":"2024-04-22T19:31:49.587771Z","iopub.status.idle":"2024-04-22T19:31:49.595342Z","shell.execute_reply.started":"2024-04-22T19:31:49.587734Z","shell.execute_reply":"2024-04-22T19:31:49.594180Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Function to calculate ROUGE scores\ndef calculate_rouge(generated_summary, actual_summary):\n    if not generated_summary:  # Check if the generated summary is empty\n        return {'rouge-1': {'p': 0, 'r': 0, 'f': 0},  # Assign zero scores\n                'rouge-2': {'p': 0, 'r': 0, 'f': 0},\n                'rouge-l': {'p': 0, 'r': 0, 'f': 0}}\n    rouge = Rouge()\n    rouge_scores = rouge.get_scores(generated_summary, actual_summary)\n    return rouge_scores[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:31:53.277376Z","iopub.execute_input":"2024-04-22T19:31:53.277802Z","iopub.status.idle":"2024-04-22T19:31:53.285148Z","shell.execute_reply.started":"2024-04-22T19:31:53.277771Z","shell.execute_reply":"2024-04-22T19:31:53.284024Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"rouge = Rouge()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(output_file, mode='w', newline='', encoding='utf-8') as output_csv:\n    csv_writer = csv.writer(output_csv)\n    csv_writer.writerow(['Text', 'Generated Summary', 'ROUGE-1 Precision', 'ROUGE-1 Recall', 'ROUGE-1 F1',\n                         'ROUGE-2 Precision', 'ROUGE-2 Recall', 'ROUGE-2 F1',\n                         'ROUGE-L Precision', 'ROUGE-L Recall', 'ROUGE-L F1'])\n\n    # Open CSV file and iterate over rows, starting from start_row and stopping at end_row\n    with open(csv_file, mode='r', newline='', encoding='utf-8') as file:\n        csv_reader = csv.DictReader(file)\n        for idx, row in enumerate(csv_reader):\n            if idx + 1 < start_row:\n                continue  # Skip rows until start_row is reached\n            if idx + 1 > end_row:\n                break  # Stop reading after reaching end_row\n\n            review_text = row['Text']\n            actual_summary = row['Summary']  # Adjust column name\n\n            # Skip rows with empty actual summary\n            if not actual_summary:\n                print(f\"Skipping row {idx + 1} due to empty Summary.\")\n                continue\n\n            # Generate summary\n            g_summary = generate_summary(review_text)\n            split_summary = g_summary.split(review_text)\n            generated_summary = split_summary[1].strip()\n\n            # Calculate ROUGE scores\n            rouge_scores = calculate_rouge(generated_summary, actual_summary)\n\n            # Write results to output file\n            csv_writer.writerow([review_text, generated_summary,\n                                 rouge_scores['rouge-1']['p'], rouge_scores['rouge-1']['r'], rouge_scores['rouge-1']['f'],\n                                 rouge_scores['rouge-2']['p'], rouge_scores['rouge-2']['r'], rouge_scores['rouge-2']['f'],\n                                 rouge_scores['rouge-l']['p'], rouge_scores['rouge-l']['r'], rouge_scores['rouge-l']['f']])\n\nprint(\"ROUGE scores calculated and saved to\", output_file)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:45:21.572345Z","iopub.execute_input":"2024-04-22T19:45:21.572812Z","iopub.status.idle":"2024-04-22T19:48:19.055895Z","shell.execute_reply.started":"2024-04-22T19:45:21.572776Z","shell.execute_reply":"2024-04-22T19:48:19.054697Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Skipping row 132 due to empty Summary.\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"ROUGE scores calculated and saved to rouge_scores.csv\n","output_type":"stream"}]}]}